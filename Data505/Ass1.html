<!DOCTYPE html>
<!-- saved from url=(0059)file:///C:/Users/paham/Downloads/PNW%20Wine%20Analysis.html -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>PNW Wine Analysis</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            text-align: justify;
        }
        pre {
            font-family: "Courier New", Courier, monospace;
            background-color: #f4f4f4;
            padding: 10px;
            border-radius: 5px;
            white-space: pre-wrap;
            word-wrap: break-word;
        }
    </style>
</head>
<body>

<h1>Assignment 1: PNW Wine Analysis</h1>
<p><strong>Author:</strong> Hannah S.K. Pahama</p>

<h2>Abstract</h2>
<p>This document analyzes wine data from select regions using R and multiple regression models.</p>

<h2>Setup</h2>
<pre><code>library(tidyverse)
library(moderndive)
</code></pre>

<pre><code>wine &lt;- readRDS(gzcon(url("https://github.com/cd-public/D505/raw/master/dat/wine.rds"))) %&gt;%
  filter(province %in% c("Oregon", 
                         "California", 
                         "New York")) %&gt;%
  mutate(
    cherry = as.integer(str_detect(description, "Cherry|cherries")),
    lprice = log(price)
  ) %&gt;%
  select(lprice, 
         points, 
         cherry, 
         province)
</code></pre>

<h2>Multiple Regression</h2>

<h3>Linear Model</h3>
<p>Here, we fit a basic linear regression model (m1) with lprice as the dependent variable and points and cherry as predictors. The model summary is then displayed along with regression summaries.</p>

<pre><code>m1 &lt;- lm(lprice ~ points + cherry,
         data = wine)
summary(m1)
get_regression_summaries(m1)
</code></pre>

<h3>Interaction Model</h3>
<p>This section adds an interaction term between points and cherry to the regression model (m2). The results and regression summaries are shown to compare the two models.</p>

<pre><code>m2 &lt;- lm(lprice ~ points * cherry, 
         data = wine)
summary(m2)
get_regression_summaries(m2)
</code></pre>

<h3>RMSE Calculation</h3>
<p>This code calculates the Root Mean Squared Error (RMSE) for the interaction model to assess its predictive performance.</p>

<pre><code>sqrt(mean(m2$residuals^2)) * 100
</code></pre>

<h3>Cherry Price Impact by Province (States: Oregon, California, or New York)</h3>
<p>This code defines a function to compute the impact of the cherry variable on lprice for each province (Oregon, California, New York). It then calculates the coefficient for each state and compares the impact across provinces.</p>

<pre><code># Define states of interest (makes life easier)
states_of_interest &lt;- c("Oregon", 
                        "California", 
                        "New York")

cherry_price_impact &lt;- function(state) {
  df &lt;- wine %&gt;% filter(province == state)
  m &lt;- lm(lprice ~ cherry, 
          data = df)
  cherry_coeff &lt;- summary(m)$coefficients["cherry", 
                                          "Estimate"]
  return(cherry_coeff)
}

# Run the function for each state in the list
results &lt;- map(states_of_interest, 
               cherry_price_impact)

# Combine the results into a data frame for easy comparison
impact_df &lt;- tibble(
  Province = states_of_interest,
  Cherry_Coefficient = unlist(results)
)

# Find the province with the highest cherry coefficient (most impact)
impact_df %&gt;% 
  arrange(desc(abs(Cherry_Coefficient))) %&gt;% 
  head(1)
</code></pre>

<h3>Coeff plot</h3>

<pre><code>library(ggplot2)

# Define states of interest (makes life easier)
states_of_interest &lt;- c("Oregon", 
                        "California", 
                        "New York")

cherry_price_impact &lt;- function(state) {
  df &lt;- wine %&gt;% filter(province == state)
  m &lt;- lm(lprice ~ cherry, 
          data = df)
  cherry_coeff &lt;- summary(m)$coefficients["cherry", 
                                          "Estimate"]
  cherry_se &lt;- summary(m)$coefficients["cherry", "Std. Error"]
  return(c(cherry_coeff, cherry_se))
}

# Run the function for each state in the list
results &lt;- map(states_of_interest, 
               cherry_price_impact)

# Combine the results into a data frame for easy comparison
impact_df &lt;- tibble(
  Province = states_of_interest,
  Cherry_Coefficient = unlist(map(results, 1)),
  SE = unlist(map(results, 2))
)

# Plot the coefficients
ggplot(impact_df, aes(x = reorder(Province, Cherry_Coefficient), 
                      y = Cherry_Coefficient, 
                      ymin = Cherry_Coefficient - 1.96 * SE, 
                      ymax = Cherry_Coefficient + 1.96 * SE)) +
  geom_pointrange() + 
  labs(title = "Impact of Cherry on Price by Province",
       x = "Province",
       y = "Cherry Coefficient (with 95% CI)") +
  theme_minimal()
</code></pre>

<h3>Bar Graph</h3>
<p>I just decided to add a visualization because I thought it would be cool. (Unnecessary but I had fun.)</p>

<pre><code>library(ggplot2)

ggplot(impact_df, 
       aes(x = reorder(Province, Cherry_Coefficient), 
           y = Cherry_Coefficient, fill = Cherry_Coefficient)) +
  geom_bar(stat = "identity", 
           color = "black", 
           size = 1) +
  labs(title = "Cherry Price Impact by Province",
       x = "Province",
       y = "Cherry Coefficient") +
  theme_minimal() +
  theme(
    plot.title = element_text(family = "Comic Sans MS", 
                                       size = 16, 
                                       face = "bold", 
                                       color = "deeppink4", 
                                       hjust = 0.5),
    axis.title = element_text(family = "Arial", 
                              size = 12, 
                              face = "italic", 
                              color = "darkgreen"),
    axis.text = element_text(family = "Arial", 
                             size = 10, 
                             color = "black"),
    panel.grid.major = element_line(color = "gray", 
                                    size = 0.2),
    panel.grid.minor = element_line(color = "lightgray", 
                                    size = 0.1),
    panel.background = element_rect(fill = "darkseagreen", 
                                    color = "black", 
                                    size = 1.5),
    legend.position = "none"
  ) +
  scale_fill_gradient(low = "white", 
                      high = "deeppink4")
</code></pre>

<h3>Model Accuracy Check</h3>
<p>This section checks the proportion of wines from New York in the dataset, helping to assess the generalizability of the model across regions.</p>

<pre><code># Directly calculate the proportion of "New York" in the province column
mean(wine$province == "New York")
</code></pre>

<h3>On Ethics</h3>
<p>Vignettes, are crucial because they help:</p>
<ul>
    <li>Highlight biases and fairness issues</li>
    <li>Test ethical boundaries</li>
    <li>Encourage everyone to uphold empathy and human impact</li>
    <li>Strengthen accountability</li>
    <li>Identify unintended consequences</li>
    <li>Communicate to different branches of professions</li>
</ul>

<h3>My stance on: Ignorance is no Excuse</h3>
<p>My approach to this would begin with understanding the specific focus and objectives of the project. In some cases, removing variables like age, income, or gender might not be unethical, particularly if the goal is to protect civilian anonymity and reduce bias. However, in a context like predicting job loss due to changing federal policies, these variables could be directly relevant to the model. They can significantly influence how individuals are impacted by policy shifts.</p>

<p>While dropping these features might help reduce potential bias and protect personal privacy, it could also make the model less accurate or less predictive. To find the right balance between ethical considerations and model performance, I would take the following steps:</p>
<ol>
    <li>Preserve the Original Data: First, I would duplicate the data to ensure the original dataset remains intact.</li>
    <li>Experiment: Next, I would run the model both with and without these variables to see how their removal affects the results.</li>
    <li>Comparison: Finally, I would compare the model outcomes to determine whether the removal of these features significantly impacts the predictive power and fairness of the model.</li>
</ol>

<p>This approach would allow me to ensure that the model remains both ethically sound and effective in terms of its predictions, while also understanding the trade-offs involved in dropping these variables.</p>

<p>Dropping these variables does not necessarily solve the ethical issue; it simply addresses one aspect of potential ethical concerns, like bias or fairness. While removing these variables can reduce the risk of discriminatory outcomes (especially if the model makes biased decisions based on these factors), it doesn't guarantee that the model is ethical or fair in its entirety.</p>




<footer>
    <p><code>-.-. --- -.. . .-. ... / -.. --- -. .----. - / - --- ..- -.-. .... / --. .-. .- ... ...</code></p>
</footer>

</body></html>
